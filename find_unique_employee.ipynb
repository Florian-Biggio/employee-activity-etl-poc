{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5252a8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, exc, text\n",
    "from sqlalchemy.engine import URL\n",
    "\n",
    "# Configuration\n",
    "DB_CONFIG = {\n",
    "    'host': 'localhost',\n",
    "    'database': 'strava_poc',\n",
    "    'user': 'strava_admin',\n",
    "    'password': 'aqwzsxedc',\n",
    "    'port': '5432'\n",
    "}\n",
    "\n",
    "HR_FILE = 'data/DonneesRH.xlsx'\n",
    "ACTIVITIES_CSV = 'strava_simulation.csv'\n",
    "\n",
    "def create_db_connection():\n",
    "    \"\"\"Create a database connection\"\"\"\n",
    "    connection_url = URL.create(\n",
    "        \"postgresql+psycopg2\",\n",
    "        username=DB_CONFIG['user'],\n",
    "        password=DB_CONFIG['password'],\n",
    "        host=DB_CONFIG['host'],\n",
    "        port=DB_CONFIG['port'],\n",
    "        database=DB_CONFIG['database']\n",
    "    )\n",
    "    return create_engine(connection_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2592db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting data validation process with corrected ID handling...\n",
      "\n",
      "SUCCESS: All activity records reference valid employees\n",
      "\n",
      "No new employees to add\n",
      "\n",
      "Sample of valid activities to process:\n",
      "   employee_id      Type               Date_de_début\n",
      "0        59019      Vélo  2024-09-27 11:10:36.283923\n",
      "1        59019  Escalade  2024-08-13 14:24:08.283923\n",
      "2        59019    Marche  2025-07-07 06:30:13.283923\n",
      "3        59019      Yoga  2024-12-20 16:05:41.283923\n",
      "4        59019      Yoga  2024-11-21 11:47:50.283923\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def main():\n",
    "    print(\"\\nStarting data validation process with corrected ID handling...\")\n",
    "    \n",
    "    try:\n",
    "        # Load HR data\n",
    "        hr_df = pd.read_excel(HR_FILE).rename(columns={\n",
    "            'ID salarié': 'employee_id',  # HR file has correct employee IDs\n",
    "            'Nom': 'last_name',\n",
    "            'Prénom': 'first_name'\n",
    "        })\n",
    "        \n",
    "        # Load Activities data - using ID_salarié as the employee reference\n",
    "        activities_df = pd.read_csv(ACTIVITIES_CSV).rename(columns={\n",
    "            'ID_salarié': 'employee_id',  # The true employee ID\n",
    "            'employee_id': 'activity_id'  # Rename the mislabeled column\n",
    "        })\n",
    "        \n",
    "        # Connect to database\n",
    "        engine = create_db_connection()\n",
    "        \n",
    "        # Verify matching IDs\n",
    "        hr_ids = set(hr_df['employee_id'])\n",
    "        activity_employee_ids = set(activities_df['employee_id'])\n",
    "        missing_ids = activity_employee_ids - hr_ids\n",
    "        \n",
    "        if missing_ids:\n",
    "            print(f\"\\nVALIDATION ISSUE: {len(missing_ids)} activity records reference non-existent employees\")\n",
    "            print(\"Sample problematic employee IDs:\", sorted(missing_ids)[:5])\n",
    "            \n",
    "            # Create diagnostic report\n",
    "            problem_records = activities_df[activities_df['employee_id'].isin(missing_ids)]\n",
    "            print(\"\\nSample problematic records:\")\n",
    "            print(problem_records[['employee_id', 'activity_id', 'Type']].head(5))\n",
    "            \n",
    "            # Calculate percentage of bad records\n",
    "            total_activities = len(activities_df)\n",
    "            bad_percentage = (len(problem_records) / total_activities) * 100\n",
    "            print(f\"\\n{len(problem_records)} of {total_activities} records ({bad_percentage:.2f}%) have invalid employee references\")\n",
    "            \n",
    "            print(\"\\nRECOMMENDED ACTIONS:\")\n",
    "            print(\"1. Verify if these employee IDs should exist in HR data\")\n",
    "            print(\"2. If these are test data, filter them out before processing\")\n",
    "            print(\"3. If these are valid employees, add them to DonneesRH.xlsx\")\n",
    "        else:\n",
    "            print(\"\\nSUCCESS: All activity records reference valid employees\")\n",
    "            \n",
    "            # Proceed with database operations\n",
    "            with engine.connect() as conn:\n",
    "                # Get existing employee IDs\n",
    "                existing_ids = pd.read_sql(\"SELECT employee_id FROM employees\", conn)['employee_id'].tolist()\n",
    "                \n",
    "                # Find new employees to add\n",
    "                new_employees = hr_df[~hr_df['employee_id'].isin(existing_ids)]\n",
    "                \n",
    "                if not new_employees.empty:\n",
    "                    print(f\"\\nInserting {len(new_employees)} new employees...\")\n",
    "                    new_employees.to_sql(\n",
    "                        'employees', \n",
    "                        engine, \n",
    "                        if_exists='append', \n",
    "                        index=False,\n",
    "                        method='multi'\n",
    "                    )\n",
    "                    print(\"Employee data successfully updated\")\n",
    "                else:\n",
    "                    print(\"\\nNo new employees to add\")\n",
    "                \n",
    "                # Process activities (example)\n",
    "                print(\"\\nSample of valid activities to process:\")\n",
    "                valid_activities = activities_df[activities_df['employee_id'].isin(hr_ids)]\n",
    "                print(valid_activities[['employee_id', 'Type', 'Date_de_début']].head(5))\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"\\nERROR: {str(e)}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2310d58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employee Data from PostgreSQL:\n",
      "     employee_id first_name  last_name  \\\n",
      "0          59019     Audrey      Colin   \n",
      "1          19841    Monique     Ledoux   \n",
      "2          56482   Michelle     Dumont   \n",
      "3          21886     Judith  Toussaint   \n",
      "4          81001   Michelle     Bailly   \n",
      "..           ...        ...        ...   \n",
      "156        18941     Gilles    Guillou   \n",
      "157        81676   Jeannine     Breton   \n",
      "158        27069   Philippe   Delahaye   \n",
      "159        30256     Odette      Dumas   \n",
      "160        94680      Henri     Pineau   \n",
      "\n",
      "                                         home_address distance_to_work  \\\n",
      "0                   128 Rue du Port, 34000 Frontignan             None   \n",
      "1      68 Rue du Port, 34970 Saint-Clément-de-Rivière             None   \n",
      "2                     100 Av. de la Gare, 30900 Nîmes             None   \n",
      "3                     53 Av. de la Gare, 34970 Lattes             None   \n",
      "4                     74 Rue des Fleurs, 34970 Lattes             None   \n",
      "..                                                ...              ...   \n",
      "156  68 Bd des Écoles, 34750 Villeneuve-lès-Maguelone             None   \n",
      "157           27 Av. du Général Leclerc, 34470 Pérols             None   \n",
      "158         59 Chem. des Pins, 34170 Castelnau-le-Lez             None   \n",
      "159                      2 Rue du Nord, 34920 Le Crès             None   \n",
      "160            5 Av. de la Liberté, 34070 Montpellier             None   \n",
      "\n",
      "                    transport_mode  birth_date         BU   hire_date  salary  \\\n",
      "0             Transports en commun  1990-07-06  Marketing  2020-12-14   30940   \n",
      "1    véhicule thermique/électrique  1962-01-06        R&D  2020-07-07   74360   \n",
      "2    véhicule thermique/électrique  1976-08-09     Ventes  2022-03-29   51390   \n",
      "3                   Marche/running  1962-09-10    Support  2021-12-12   70320   \n",
      "4                   Marche/running  1975-04-20     Ventes  2025-02-19   46870   \n",
      "..                             ...         ...        ...         ...     ...   \n",
      "156        Vélo/Trottinette/Autres  1986-12-23    Finance  2025-02-27   59910   \n",
      "157                 Marche/running  1966-06-24     Ventes  2022-01-22   48430   \n",
      "158  véhicule thermique/électrique  1996-09-10    Support  2020-11-27   56380   \n",
      "159  véhicule thermique/électrique  1960-12-22     Ventes  2023-04-08   45170   \n",
      "160        Vélo/Trottinette/Autres  1973-11-16  Marketing  2025-01-24   64180   \n",
      "\n",
      "    contract_type  vacation_days  \n",
      "0             CDI             29  \n",
      "1             CDI             26  \n",
      "2             CDI             27  \n",
      "3             CDI             29  \n",
      "4             CDD             29  \n",
      "..            ...            ...  \n",
      "156           CDI             29  \n",
      "157           CDI             29  \n",
      "158           CDI             29  \n",
      "159           CDI             29  \n",
      "160           CDD             26  \n",
      "\n",
      "[161 rows x 12 columns]\n",
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 161 entries, 0 to 160\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   employee_id       161 non-null    int64 \n",
      " 1   first_name        161 non-null    object\n",
      " 2   last_name         161 non-null    object\n",
      " 3   home_address      161 non-null    object\n",
      " 4   distance_to_work  0 non-null      object\n",
      " 5   transport_mode    161 non-null    object\n",
      " 6   birth_date        161 non-null    object\n",
      " 7   BU                161 non-null    object\n",
      " 8   hire_date         161 non-null    object\n",
      " 9   salary            161 non-null    int64 \n",
      " 10  contract_type     161 non-null    object\n",
      " 11  vacation_days     161 non-null    int64 \n",
      "dtypes: int64(3), object(9)\n",
      "memory usage: 15.2+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Database configuration\n",
    "DB_CONFIG = {\n",
    "    'host': 'localhost',\n",
    "    'database': 'strava_poc',\n",
    "    'user': 'strava_admin',\n",
    "    'password': 'aqwzsxedc',\n",
    "    'port': '5432'\n",
    "}\n",
    "\n",
    "# Create connection and fetch data\n",
    "try:\n",
    "    # Create engine\n",
    "    engine = create_engine(\n",
    "        f\"postgresql+psycopg2://{DB_CONFIG['user']}:{DB_CONFIG['password']}@\"\n",
    "        f\"{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}\"\n",
    "    )\n",
    "    \n",
    "    # Query all employees\n",
    "    employees_df = pd.read_sql(\"SELECT * FROM employees\", engine)\n",
    "    \n",
    "    # Display the DataFrame\n",
    "    print(\"Employee Data from PostgreSQL:\")\n",
    "    print(employees_df)\n",
    "    \n",
    "    # Optional: Show DataFrame info\n",
    "    print(\"\\nDataFrame Info:\")\n",
    "    employees_df.info()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error accessing database: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0cab438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File successfully prepared at: C:/temp/strava_ready_to_import.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def prepare_strava_data(input_path, output_path):\n",
    "    # Read the CSV with proper encoding\n",
    "    df = pd.read_csv(input_path, encoding='utf-8-sig')\n",
    "    \n",
    "    # Standardize column names\n",
    "    column_map = {\n",
    "        'ID_salarié': 'employee_id',\n",
    "        'Date_de_début': 'start_date',\n",
    "        'Type': 'sport_type',\n",
    "        'Distance': 'distance_meters',\n",
    "        'Date_de_fin': 'end_date',\n",
    "        'Commentaire': 'comment'\n",
    "    }\n",
    "    df = df.rename(columns={k: v for k, v in column_map.items() if k in df.columns})\n",
    "    \n",
    "    # Calculate elapsed time if both dates exist\n",
    "    if 'start_date' in df.columns and 'end_date' in df.columns:\n",
    "        df['elapsed_time_seconds'] = (\n",
    "            pd.to_datetime(df['end_date']) - \n",
    "            pd.to_datetime(df['start_date'])\n",
    "        ).dt.total_seconds().astype(int)\n",
    "    \n",
    "    # Select only the columns we want to import (exclude id and is_valid)\n",
    "    final_columns = [\n",
    "        'employee_id',\n",
    "        'start_date',\n",
    "        'sport_type',\n",
    "        'distance_meters',\n",
    "        'elapsed_time_seconds',\n",
    "        'end_date',\n",
    "        'comment'\n",
    "    ]\n",
    "    df = df[[col for col in final_columns if col in df.columns]]\n",
    "    \n",
    "    # Save with proper header and no index\n",
    "    df.to_csv(output_path, index=False, encoding='utf-8')\n",
    "    print(f\"File successfully prepared at: {output_path}\")\n",
    "\n",
    "# Usage\n",
    "prepare_strava_data(\n",
    "    input_path='C:/temp/strava_simulation.csv',\n",
    "    output_path='C:/temp/strava_ready_to_import.csv'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
